{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from encoders.cgan import *\n",
    "from datetime import datetime\n",
    "from encoders.stn import Localization, BilinearInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "backgrounds = load_imgs(\"data/bottle/train/background/\")\n",
    "paired = load_imgs(\"data/bottle/train/composite/\")\n",
    "objects = load_imgs(\"data/bottle/train/foreground/\")\n",
    "depth = load_imgs(\"data/bottle/train/depth/\")\n",
    "print('Loaded train: ', backgrounds.shape, paired.shape, objects.shape)\n",
    "\n",
    "# Define data\n",
    "data = [backgrounds, paired, objects, depth]\n",
    "dataset = preprocess_data(data)\n",
    "\n",
    "'''\n",
    "val_backgrounds = load_imgs(\"data/bottle/val/background/\")\n",
    "val_paired = load_imgs(\"data/bottle/val/composite/\")\n",
    "val_objects = load_imgs(\"data/bottle/val/foreground/\")\n",
    "val_depth = load_imgs(\"data/bottle/val/depth/\")\n",
    "print('Loaded validation: ', val_backgrounds.shape, val_paired.shape, val_objects.shape)\n",
    "\n",
    "val_data = [val_backgrounds, val_paired, val_objects, val_depth]\n",
    "val_dataset = preprocess_data(val_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3\n",
    "n_rows = 4\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Plot background images\n",
    "    pyplot.subplot(n_rows, n_samples, 1 + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(backgrounds[i].astype('uint8'))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Plot target images (paired)\n",
    "    pyplot.subplot(n_rows, n_samples, 1 + n_samples + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(paired[i].astype('uint8'))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Add another axis of images (replace 'additional_images' with the actual array)\n",
    "    pyplot.subplot(n_rows, n_samples, 1 + 3 * n_samples + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(objects[i].astype('uint8'))  # Replace 'additional_images' with your array\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "VAL_SAMPLES = 3 # Number of validation samples\n",
    "VAL_FREQUENCY = 70000 # Perform validation every x step\n",
    "EPOCHS = 1000 # Number of epochs\n",
    "BATCH_SIZE = 1 # Batch size\n",
    "D_LR = 0.0001 # Discriminator learning rate\n",
    "G_LR = 0.0002 # Generator learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STN Sanity check\n",
    "STN_CHECK = False\n",
    "\n",
    "if STN_CHECK:\n",
    "\tprocessed = (objects - 127.5) / 127.5\n",
    "\ttheta = Localization()(processed)\n",
    "\tprint(theta)\n",
    "\tx = BilinearInterpolation(height=256, width=256)([processed, theta])\n",
    "\n",
    "\t# Display the original and transformed images\n",
    "\tplt.figure(figsize=(10, 4))\n",
    "\t# Display the original image\n",
    "\tplt.subplot(1, 3, 1)\n",
    "\toriginal_img = processed[0]  # Assuming x is in the range [-1, 1]\n",
    "\tplt.imshow(original_img)\n",
    "\tplt.title('Original Image')\n",
    "\tplt.axis('off')\n",
    "\t# Display the transformed image\n",
    "\tplt.subplot(1, 3, 2)\n",
    "\ttransformed_img = x[0]  # Assuming output is in the range [-1, 1]\n",
    "\tplt.imshow(transformed_img)\n",
    "\tplt.title('Transformed Image')\n",
    "\tplt.axis('off')\n",
    "\tplt.subplot(1, 3, 3)\n",
    "\ttransformed_img = x[1]  # Assuming output is in the range [-1, 1]\n",
    "\tplt.imshow(transformed_img)\n",
    "\tplt.title('Transformed Image')\n",
    "\tplt.axis('off')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape based on the loaded dataset\n",
    "image_shape = backgrounds.shape[1:]\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape, D_LR)\n",
    "g_model = define_generator(image_shape, False)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape, G_LR)\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "train(d_model, g_model, gan_model, dataset, VAL_SAMPLES, VAL_FREQUENCY, EPOCHS, BATCH_SIZE)\n",
    "\n",
    "stop = datetime.now()\n",
    "#Execution time of the model\n",
    "execution_time = stop-start\n",
    "print(\"Execution time is: \", execution_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
